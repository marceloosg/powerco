---
title: "Power Co Exploratory Analysis"
output: html_notebook
---

#Libraries
```{r}
library(data.table)
library(RANN)
library(e1071)
source("functions.R")
```



#Load Data
```{r}
data=fread('train/ml_case_training_data.csv')
output=fread('train/ml_case_training_output.csv')
hist=fread('train/ml_case_training_hist_data.csv')
summary(data)
```


```{r,cache=TRUE}
preprocess_model=preprocess_train_pipeline(data)
```
```{r}
save(preprocess_model,file="preprocessing.model.RData")
```


```{r,cache=TRUE}
plot_explain_variance(preprocess_model)
```

```{r}
plot_cum_explain_variance(preprocess_model)
```

# Let's see how accurate pca can reconstruct the binary matrix with just 15 dimensions
```{r}
pca_accuracy(preprocess_model)
```

# Are the low accuracy columns those correlated?
```{r}
corrplot::corrplot(cor(preprocess_model$data$combined$binaries[,preprocess_model$fit$pca$bin_accuracy[accurate==F]$names,with=F]))
```

```{r}
pca_accuracy(preprocess_model,F)
```

# Are the low accuracy columns those correlated?
```{r}
corrplot::corrplot(cor(preprocess_model$data$output$imputed_values[,preprocess_model$fit$pca$val_accuracy[accurate==F]$names,with=F]))
```

```{r}
preprocessed_training_data=preprocess_predict_pipeline(model,data)
dim(preprocessed_training_data$results)
```

#Exploration:
```{r}
data.table(t(preprocessed_training_data$data$raw$values[,lapply(.SD,function(s) cor(s[!is.na(s)],output[!is.na(s)]$churn))]),keep.rownames = T)[order(-abs(V1))]
```
```{r}
values=(data.table(t(preprocessed_training_data$data$raw$values[,lapply(.SD,function(s) 
  c("m"=mean(s,na.rm=T),"s"=sd(s,na.rm=T))
  ), output$churn]),keep.rownames = T))
v=values[rn!="output",.(rn,r=V3/V4-V1/V2)][order(-abs(r))]
v
```
```{r}
library(MASS)
dd=cbind(preprocessed_training_data$data$raw$values[,v[1:3]$rn,with=F],output[,churn])
dd=dd[complete.cases(dd)]
ds=rbind(dd[V2==1],dd[V2==0][sample(1:dim(dd[V2==0])[1],size=dim(dd[V2==1])[1])])
lmod=randomForest::randomForest(factor(V2) ~ .,data=ds)

table(predict(lmod))


```


```{r}
date_churn=cbind(model$data$output$id,get_dates(data,model$fit$structure_model$indexes,F))
date_churn=merge(date_churn,output,by="id")
date_churn[,mean(churn),month(date_end)][order(-V1)]
```
```{r}
date_churn[,.(.N,mean(V2)),year(date_end)][order(-V2)]
```
```{r}

```


# Training
## split
```{r}
result=merge(preprocessed_training_data$results,output,by="id")
set.seed(814)0
index = createDataPartition(y=output$churn, p=0.7, list=FALSE )

train = result[index,-c("id")]
test = result[-index,-c("id")]
```

#Baysian
```{r}
set.seed(814)
nb.fit = train(as.factor(churn) ~ ., data=train, method="nb",
                trControl = trainControl(method = "cv"))
z=predict(nb.fit)
confusionMatrix(z,as.factor(train$churn))
```

#LDA
```{r}
set.seed(814)
lda.fit = train(as.factor(churn) ~ ., data=train, method="lda",
                trControl = trainControl(method = "cv"))
z=predict(lda.fit)
confusionMatrix(z,factor(train$churn))
```

```{r}
set.seed(814)
ctrl <- trainControl(method = "cv", 
                     number = 7, 
                     verboseIter = FALSE,
                     sampling = "down")
down.lda.fit = train(as.factor(churn) ~ ., data=train, method="lda",
                trControl = ctrl)
z=predict(down.lda.fit)
confusionMatrix(z,factor(train$churn))
```
```{r}
set.seed(814)
ctrl <- trainControl(method = "cv", 
                     number = 7, 
                     verboseIter = FALSE,
                     sampling = "up")
lda.fit = train(as.factor(churn) ~ ., data=train, method="lda",
                trControl = ctrl)
table(predict(lda.fit),train$churn)
```

#RF
```{r}
rf.fit = train(as.factor(churn) ~ ., data=train, method="rf",
                trControl = trainControl(method = "cv"))
table(predict(rf.fit),train$churn)
```
```{r}
confusionMatrix(predict(rf.fit,test),factor(test$churn),positive = "1")

```

